import gradio as gr
import torch
import gc
from PIL import Image
import time
import traceback

# å»¶è¿ŸåŠ è½½åŒ…è£…å™¨ï¼ˆå¸¦æ˜¾å­˜æ¸…ç†ï¼‰
class ModelLoader:
    def __init__(self):
        self.text2img_gen = None
        self.img2img_gen = None
        self.inpaint_gen = None
        self.monitor = None
        self.current_model = None  # è¿½è¸ªå½“å‰åŠ è½½çš„æ¨¡å‹
    
    def unload_current_model(self):
        """å¼ºåˆ¶å¸è½½å½“å‰æ¨¡å‹å¹¶æ¸…ç†æ˜¾å­˜"""
        if self.current_model == "text2img" and self.text2img_gen is not None:
            print("ğŸ§¹ å¸è½½æ–‡ç”Ÿå›¾æ¨¡å‹...")
            del self.text2img_gen
            self.text2img_gen = None
        elif self.current_model == "img2img" and self.img2img_gen is not None:
            print("ğŸ§¹ å¸è½½å›¾ç”Ÿå›¾æ¨¡å‹...")
            del self.img2img_gen
            self.img2img_gen = None
        elif self.current_model == "inpaint" and self.inpaint_gen is not None:
            print("ğŸ§¹ å¸è½½ä¿®å¤æ¨¡å‹...")
            del self.inpaint_gen
            self.inpaint_gen = None
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶å’Œæ˜¾å­˜æ¸…ç†
        gc.collect()
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()
        self.current_model = None
        print(f"âœ“ æ˜¾å­˜å·²æ¸…ç†ï¼Œå½“å‰å ç”¨: {torch.cuda.memory_allocated()/1024**3:.2f}GB")
    
    def get_text2img(self):
        if self.text2img_gen is None:
            self.unload_current_model()  # å…ˆæ¸…ç†
            print("ğŸ”„ åŠ è½½æ–‡ç”Ÿå›¾æ¨¡å‹...")
            from core.text2img import Text2ImageGenerator
            self.text2img_gen = Text2ImageGenerator()
            self.current_model = "text2img"
        return self.text2img_gen
    
    def get_img2img(self):
        if self.img2img_gen is None:
            self.unload_current_model()  # å…ˆæ¸…ç†
            print("ğŸ”„ åŠ è½½å›¾ç”Ÿå›¾æ¨¡å‹...")
            from core.img2img_controlnet import Image2ImageControlNetGenerator
            self.img2img_gen = Image2ImageControlNetGenerator()
            self.current_model = "img2img"
        return self.img2img_gen
    
    def get_inpaint(self):
        if self.inpaint_gen is None:
            self.unload_current_model()  # å…ˆæ¸…ç†
            print("ğŸ”„ åŠ è½½ä¿®å¤æ¨¡å‹...")
            from core.inpaint import ImageInpainter
            self.inpaint_gen = ImageInpainter()
            self.current_model = "inpaint"
        return self.inpaint_gen
    
    def get_monitor(self):
        if self.monitor is None:
            from core.monitor import SystemMonitor
            self.monitor = SystemMonitor()
        return self.monitor

loader = ModelLoader()

def generate_text2img(prompt, negative, width, height, steps, guidance, seed):
    """æ–‡ç”Ÿå›¾æ¥å£"""
    try:
        seed = int(seed)
        steps = int(steps)
        width = int(width)
        height = int(height)
        guidance = float(guidance)
        
        gen = loader.get_text2img()
        
        result = gen.generate(prompt, negative, width, height, steps, guidance, seed)
        current_mem = torch.cuda.memory_allocated() / 1024**3
        
        return result["image"], f"âœ“ ç”ŸæˆæˆåŠŸï¼æ˜¾å­˜: {current_mem:.2f}GB (å³°å€¼: {result['memory_gb']:.2f}GB)"
    except Exception as e:
        error_msg = f"âŒ é”™è¯¯: {str(e)}"
        print(traceback.format_exc())
        return None, error_msg

def generate_img2img(init_image, prompt, negative, strength, steps, guidance, seed):
    """å›¾ç”Ÿå›¾æ¥å£"""
    try:
        if init_image is None:
            return None, "âŒ é”™è¯¯: è¯·å…ˆä¸Šä¼ å›¾ç‰‡"
        
        seed = int(seed)
        steps = int(steps)
        strength = float(strength)
        guidance = float(guidance)
        
        gen = loader.get_img2img()
        
        result = gen.generate(init_image, prompt, negative, strength, steps, guidance, seed)
        current_mem = torch.cuda.memory_allocated() / 1024**3
        
        return result["image"], f"âœ“ è½¬æ¢æˆåŠŸï¼æ˜¾å­˜: {current_mem:.2f}GB"
    except Exception as e:
        error_msg = f"âŒ é”™è¯¯: {str(e)}"
        print(traceback.format_exc())
        return None, error_msg

def generate_inpaint(image, mask, prompt, steps, guidance, seed):
    """å›¾åƒä¿®å¤æ¥å£"""
    try:
        if image is None:
            return None, "âŒ é”™è¯¯: è¯·å…ˆä¸Šä¼ æŸåå›¾ç‰‡"
        
        seed = int(seed)
        steps = int(steps)
        guidance = float(guidance)
        
        gen = loader.get_inpaint()
        
        if mask is None:
            mask = Image.new("L", image.size, 0)
        
        result = gen.inpaint(image, mask, prompt, steps=steps, guidance=guidance, seed=seed)
        current_mem = torch.cuda.memory_allocated() / 1024**3
        
        return result["image"], f"âœ“ ä¿®å¤æˆåŠŸï¼æ˜¾å­˜: {current_mem:.2f}GB"
    except Exception as e:
        error_msg = f"âŒ é”™è¯¯: {str(e)}"
        print(traceback.format_exc())
        return None, error_msg

def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        monitor = loader.get_monitor()
        status = monitor.get_status()
        return (
            f"{status.get('gpu_mem_used', 'N/A')}/{status.get('gpu_mem_total', 'N/A')}",
            status.get('gpu_util', 'N/A'),
            f"{status.get('cpu_mem_used', 'N/A')}/{status.get('cpu_mem_total', 'N/A')}",
            "è¿è¡Œä¸­"
        )
    except Exception as e:
        return ("N/A", "N/A", "N/A", f"é”™è¯¯: {str(e)}")

# ========== ç•Œé¢éƒ¨åˆ†ä¿æŒä¸å˜ ==========
with gr.Blocks(title="Stable Diffusionæ¯•ä¸šè®¾è®¡ç³»ç»Ÿ", css="footer {visibility: hidden}") as demo:
    gr.Markdown("""
    # ğŸ¨ Stable Diffusion å›¾åƒç”Ÿæˆä¸å¤„ç†ç³»ç»Ÿ
    *åŸºäºæ¶ˆè´¹çº§GPUçš„è½»é‡åŒ–éƒ¨ç½² - æ¯•ä¸šè®¾è®¡é¡¹ç›®*
    """)
    
    with gr.Tabs():
        with gr.TabItem("æ–‡ç”Ÿå›¾"):
            with gr.Row():
                with gr.Column():
                    prompt_t2i = gr.Textbox(label="æ­£å‘æç¤ºè¯", placeholder="è¾“å…¥æè¿°ï¼Œå¦‚ï¼ša cute cat", lines=3)
                    negative_t2i = gr.Textbox(label="åå‘æç¤ºè¯", value="low quality, blurry", lines=2)
                    with gr.Row():
                        width_t2i = gr.Slider(256, 768, 512, step=64, label="å®½åº¦")
                        height_t2i = gr.Slider(256, 768, 512, step=64, label="é«˜åº¦")
                    steps_t2i = gr.Slider(10, 50, 25, step=1, label="é‡‡æ ·æ­¥æ•°")
                    guidance_t2i = gr.Slider(5, 15, 7.5, step=0.5, label="å¼•å¯¼ç³»æ•°")
                    seed_t2i = gr.Number(-1, label="éšæœºç§å­(-1è¡¨ç¤ºéšæœº)", precision=0)
                    btn_t2i = gr.Button("ğŸ¨ ç”Ÿæˆå›¾åƒ", variant="primary")
                
                with gr.Column():
                    output_t2i = gr.Image(label="ç”Ÿæˆç»“æœ")
                    status_t2i = gr.Textbox(label="çŠ¶æ€ä¿¡æ¯", interactive=False)
            
            btn_t2i.click(
                generate_text2img,
                inputs=[prompt_t2i, negative_t2i, width_t2i, height_t2i, steps_t2i, guidance_t2i, seed_t2i],
                outputs=[output_t2i, status_t2i]
            )
        
        with gr.TabItem("å›¾ç”Ÿå›¾(ControlNet)"):
            with gr.Row():
                with gr.Column():
                    init_img_i2i = gr.Image(label="ä¸Šä¼ åŸå›¾", type="pil")
                    prompt_i2i = gr.Textbox(label="é£æ ¼æç¤ºè¯", placeholder="cyberpunk style, neon lights", lines=2)
                    negative_i2i = gr.Textbox(label="åå‘æç¤ºè¯", value="blurry, low quality", lines=2)
                    strength_i2i = gr.Slider(0.1, 1.0, 0.65, step=0.05, label="é‡ç»˜å¹…åº¦")
                    steps_i2i = gr.Slider(10, 50, 25, step=1, label="é‡‡æ ·æ­¥æ•°")
                    guidance_i2i = gr.Slider(5, 15, 8.0, step=0.5, label="å¼•å¯¼ç³»æ•°")
                    seed_i2i = gr.Number(-1, label="éšæœºç§å­", precision=0)
                    btn_i2i = gr.Button("ğŸ”„ é£æ ¼è½¬æ¢", variant="primary")
                
                with gr.Column():
                    output_i2i = gr.Image(label="è½¬æ¢ç»“æœ")
                    status_i2i = gr.Textbox(label="çŠ¶æ€ä¿¡æ¯", interactive=False)
            
            btn_i2i.click(
                generate_img2img,
                inputs=[init_img_i2i, prompt_i2i, negative_i2i, strength_i2i, steps_i2i, guidance_i2i, seed_i2i],
                outputs=[output_i2i, status_i2i]
            )
        
        with gr.TabItem("å›¾åƒä¿®å¤"):
            with gr.Row():
                with gr.Column():
                    image_inpaint = gr.Image(label="ä¸Šä¼ æŸåå›¾", type="pil")
                    mask_inpaint = gr.Image(label="ä¸Šä¼ maskå›¾ï¼ˆå¯é€‰ï¼‰", type="pil")
                    prompt_inpaint = gr.Textbox(label="ä¿®å¤æç¤ºè¯", placeholder="orange cat, natural fur, high quality", lines=2)
                    steps_inpaint = gr.Slider(10, 50, 35, step=1, label="é‡‡æ ·æ­¥æ•°")
                    guidance_inpaint = gr.Slider(5, 15, 8.0, step=0.5, label="å¼•å¯¼ç³»æ•°")
                    seed_inpaint = gr.Number(-1, label="éšæœºç§å­", precision=0)
                    btn_inpaint = gr.Button("ğŸ”§ æ™ºèƒ½ä¿®å¤", variant="primary")
                
                with gr.Column():
                    output_inpaint = gr.Image(label="ä¿®å¤ç»“æœ")
                    status_inpaint = gr.Textbox(label="çŠ¶æ€ä¿¡æ¯", interactive=False)
            
            btn_inpaint.click(
                generate_inpaint,
                inputs=[image_inpaint, mask_inpaint, prompt_inpaint, steps_inpaint, guidance_inpaint, seed_inpaint],
                outputs=[output_inpaint, status_inpaint]
            )
        
        with gr.TabItem("ç³»ç»Ÿç›‘æ§"):
            gr.Markdown("### å®æ—¶æ€§èƒ½ç›‘æ§")
            with gr.Row():
                gpu_mem = gr.Textbox(label="GPUæ˜¾å­˜", interactive=False)
                gpu_util = gr.Textbox(label="GPUå ç”¨ç‡", interactive=False)
                cpu_mem = gr.Textbox(label="CPUå†…å­˜", interactive=False)
            
            refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°çŠ¶æ€")
            refresh_btn.click(get_system_status, outputs=[gpu_mem, gpu_util, cpu_mem])

if __name__ == "__main__":
    demo.launch(server_name="127.0.0.1", server_port=7860, share=False, show_error=True)